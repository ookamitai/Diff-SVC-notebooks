{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfX4jAjOCAJlX3KFDsA7Gb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Archivoice/Diff-SVC-notebooks/blob/main/Diff_SVC_inference_notebook_(colab_ver_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference notebook for [Diff-SVC](https://github.com/prophesier/diff-svc) written by [Nekro](https://twitter.com/NekroTheCorpse) of [Archivoice](https://github.com/archivoice)\n"
      ],
      "metadata": {
        "id": "utdycYwDl473"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Setup"
      ],
      "metadata": {
        "id": "G6guqBnrD3qb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WcC2XWVgC4T0"
      },
      "outputs": [],
      "source": [
        "#@title #Check GPU type\n",
        "#@markdown At this stage it's not really necessary, the best it does is let you guess how fast it can render\n",
        "#@markdown ####¯\\\\_(ツ)_/¯\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Mount Google Drive\n",
        "\n",
        "#@markdown Makes your life easier when uploading and saving stuff.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "!rm -rf /content/drive\n",
        "drive.mount('/content/drive')\n",
        "print('Done!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VSyF4oZhDxgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Install Diff-SVC\n",
        "#@markdown The stuff you'll need for every other thing afterwards.\n",
        "\n",
        "from IPython.display import clear_output \n",
        "from google.colab import files \n",
        "import os\n",
        "print('Upgrading pip & installing 7zip')\n",
        "!rm -rf /content/sample_data\n",
        "!python -m pip install --upgrade pip\n",
        "!python -m pip install --upgrade wheel\n",
        "!apt-get install unzip\n",
        "!pip install gdown\n",
        "\n",
        "print('Installing torch')\n",
        "%pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "!pip install --pre torchtext==0.6.0 --no-deps\n",
        "\n",
        "print('Installing Diff-SVC')\n",
        "!git clone https://github.com/prophesier/diff-svc &> /dev/null\n",
        "%cd \n",
        "\n",
        "print('Installing requirements')\n",
        "%cd \"/content/diff-svc/\"\n",
        "!pip install -r requirements_short.txt\n",
        "!pip install tensorboard<2.9,>=2.8\n",
        "%reload_ext tensorboard\n",
        "\n",
        "%cd \"/content/diff-svc/training/\"\n",
        "!rm config.yaml\n",
        "!gdown 'https://drive.google.com/uc?id=1FeYxQZI-n-_GLPktq1aEVzXH0IM7_i3F' -O config.yaml\n",
        "%cd \"/content/\"\n",
        "# !gdown 'https://drive.google.com/uc?id=1MqxItZvE7Xf-ae5QeW9nsfK7qzyOx5KH' -O checkpoints.zip\n",
        "%mkdir -p /content/diff-svc/checkpoints/\n",
        "!unzip /content/drive/MyDrive/checkpoints.zip -d /content/diff-svc/\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "IYxufeQ9EKuY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Load singer model\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Load in the full path of your model and config.  \n",
        "\n",
        "#@markdown `project_name` is the name of your singer, `model_path`, as the name states, is the path directory to your model (full path), same goes for `config_path`.\n",
        "\n",
        "#@markdown Ex:\n",
        "\n",
        "#@markdown project_name = test\n",
        "\n",
        "#@markdown model_path = /content/drive/MyDrive/Diff-SVC/checkpoints/test/model_ckpt_steps_50000.ckpt\n",
        "\n",
        "#@markdown config_path = /content/drive/MyDrive/Diff-SVC/checkpoints/test/config.yaml\n",
        "\n",
        "#@markdown The model below is a default model, change the settings to use your own model.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "%cd \"/content/diff-svc/\"\n",
        "\n",
        "os.environ['PYTHONPATH']='.'\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0\n",
        "from utils.hparams import hparams\n",
        "from preprocessing.data_gen_utils import get_pitch_parselmouth,get_pitch_crepe\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import utils\n",
        "import librosa\n",
        "import torchcrepe\n",
        "from infer import *\n",
        "import logging\n",
        "from infer_tools.infer_tool import *\n",
        "\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "\n",
        "project_name = \"nyaru\" #@param {type: \"string\"}\n",
        "model_path = \"./checkpoints/nyaru/model_ckpt_steps_112000.ckpt\" #@param {type: \"string\"}\n",
        "config_path=\"./checkpoints/nyaru/config.yaml\" #@param {type: \"string\"}\n",
        "hubert_gpu=True\n",
        "svc_model = Svc(project_name,config_path,hubert_gpu, model_path)\n",
        "print('model loaded')"
      ],
      "metadata": {
        "id": "CEWhfwEmLoQx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rendering\n",
        "Finally, the fun part."
      ],
      "metadata": {
        "id": "4s-RqXnR-UOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Upload audio here\n",
        "\n",
        "%cd \"/content/diff-svc/raw/\"\n",
        "\n",
        "print(\"\\n\\033[34m\\033[1mupload your audio\")\n",
        "listfn, length = files.upload().popitem()\n",
        "\n",
        "%cd \"/content/diff-svc/\"\n",
        "print(\"\\n\\033[32m\\033[1mdone\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NvlB1oCR_lxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Input audio and adjust parameters\n",
        "#@markdown Additional parameters can be adjusted by double-clicking this cell.\n",
        "#@markdown ___\n",
        "#@markdown *Note: Read the document on the Github page for more detailed info on adjusting the values*\n",
        "#@markdown ___\n",
        "\n",
        "wav_fn='raw/test_input.wav' #@param {type: \"string\"}\n",
        "#@markdown (input file name.)\n",
        "demoaudio, sr = librosa.load(wav_fn)\n",
        "key = 0#@param {type: \"integer\"}\n",
        "#@markdown (key basically shifts the reference audio up or down by semitone, postitive and negative values are ok.)\n",
        "pndm_speedup = 20 #@param {type: \"integer\"}\n",
        "#@markdown (pndm_speedup adjusts the rendering speed at the stake of audio quality, default works fine unless you're in a hurry.)\n",
        "wav_gen='test_output.wav' #@param {type: \"string\"}\n",
        "#@markdown (output file name.)\n",
        "f0_tst, f0_pred, audio = run_clip(svc_model,file_path=wav_fn, key=key, acc=pndm_speedup, use_crepe=True, use_pe=True, thre=0.05,\n",
        "                                        use_gt_mel=False, add_noise_step=500,project_name=project_name,out_path=wav_gen)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iL_l99IviZjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Display results\n",
        "ipd.display(ipd.Audio(demoaudio, rate=sr))\n",
        "ipd.display(ipd.Audio(audio, rate=hparams['audio_sample_rate'], normalize=False))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TmyizAKvlt0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Display graph\n",
        "\n",
        "#f0_gen,_=get_pitch_crepe(*vocoder.wav2spec(wav_gen),hparams,threshold=0.05)\n",
        "%matplotlib inline\n",
        "f0_gen,_=get_pitch_parselmouth(*svc_model.vocoder.wav2spec(wav_gen),hparams)\n",
        "f0_tst[f0_tst==0]=np.nan#ground truth f0\n",
        "f0_pred[f0_pred==0]=np.nan#f0 pe predicted\n",
        "f0_gen[f0_gen==0]=np.nan#f0 generated\n",
        "fig=plt.figure(figsize=[15,5])\n",
        "plt.plot(np.arange(0,len(f0_tst)),f0_tst,color='black')\n",
        "plt.plot(np.arange(0,len(f0_pred)),f0_pred,color='orange')\n",
        "plt.plot(np.arange(0,len(f0_gen)),f0_gen,color='red')\n",
        "plt.axhline(librosa.note_to_hz('C4'),ls=\":\",c=\"blue\")\n",
        "plt.axhline(librosa.note_to_hz('G4'),ls=\":\",c=\"green\")\n",
        "plt.axhline(librosa.note_to_hz('C5'),ls=\":\",c=\"orange\")\n",
        "plt.axhline(librosa.note_to_hz('F#5'),ls=\":\",c=\"red\")\n",
        "#plt.axhline(librosa.note_to_hz('A#5'),ls=\":\",c=\"black\")\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LOb63fihluyT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
